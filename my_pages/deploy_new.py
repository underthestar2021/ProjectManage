import json
import math
import re
import uuid
from collections import defaultdict
from datetime import datetime, timedelta
from uuid import uuid4

import requests
import streamlit as st
import pandas as pd
from deepdiff import DeepDiff

from config import CONFIG
from database.sqlite import SQLiteOp
from util import init_session_state, get_env_pg, init_pg, get_env_pg_user_info, get_user_id, get_pg, get_sqlite, \
    get_fuse_pg


def get_folder_info_by_sql(env, user_id, with_backups=False):
    current_pg = get_env_pg(env)
    sql = "SELECT name, id FROM folder where user_id=%s"
    if with_backups:
        sql += " and (RIGHT(name, 1)='*' or name='å¤‡ä»½')"
    else:
        sql += " and RIGHT(name, 1)='*'"
    result = current_pg.execute_query(sql, (user_id,))
    current_pg.commit()
    return result


def get_folder_info_by_api(langflow_token, base_url):
    url = f"{base_url}/api/v1/projects/"
    response = requests.get(url, headers={"Authorization": f'Bearer {langflow_token}'})
    dir_dict = {i['name']: i['id'] for i in response.json()}
    return dir_dict


@st.cache_data(ttl=300)
def login_langflow(username, password, url):
    payload = f'username={username}&password={password}'
    headers = {
        'Content-Type': 'application/x-www-form-urlencoded',
        'Accept': 'application/json'
    }
    response = requests.request("POST", url + "/api/v1/login", headers=headers,
                                data=payload)
    return response.json()['access_token']


def create_folder_by_api(langflow_token, folder_name, base_url):
    data = {"name": folder_name, "description": "", "flows_list": [], "components_list": []}
    url = f"{base_url}/api/v1/projects/"
    response = requests.post(url, headers={"Authorization": f'Bearer {langflow_token}'}, json=data)
    if response.status_code == 201:
        st.success(f"åˆ›å»º{folder_name}ç›®å½•æˆåŠŸ")
        dir_id = response.json()["id"]
        return dir_id
    else:
        st.error(f"åˆ›å»º{folder_name}ç›®å½•å¤±è´¥, {response.text}")


def create_new_flow_by_api(langflow_token, folder_id, one, base_url):
    new_data = {
        "name": one["name"],
        "description": one["description"],
        "data": one["data"],
        "endpoint_name": one["endpoint_name"],
        "gradient": one["gradient"],
        "is_component": one["is_component"],
        "tags": one["tags"],
        "mcp_enabled": True,
        "folder_id": folder_id,
        "icon": None,
    }
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {langflow_token}'
    }
    response = requests.post(f"{base_url}/api/v1/flows/", headers=headers, json=new_data)

    if response.status_code == 201:
        st.success(f"æ–°å»º {new_data['name']} æˆåŠŸ")
        return response.json()
    else:
        st.error(f"æ–°å»º {new_data['name']} å¤±è´¥, {response.text}")
        return {}


@st.fragment
def get_data(search_term, user_id, folder_id, env, begin_time):
    sql = ("left join folder on flow.user_id=folder.user_id and flow.folder_id=folder.id WHERE flow.is_component=False "
           "AND folder.user_id='{}' and RIGHT(folder.name, 1)='*'").format(user_id)
    if folder_id:
        sql += f" AND flow.folder_id = '{folder_id}'"
    if begin_time:
        sql += f" AND flow.updated_at >= '{begin_time}'"
    if search_term:
        sql += f" AND flow.name ILIKE '%{search_term}%'"
    pg = get_env_pg(env)
    query = (("SELECT flow.name, folder.name, flow.description,flow.updated_at,flow.endpoint_name,"
              "flow.gradient,flow.is_component,flow.tags,flow.data FROM flow ") + sql +
             f" ORDER BY updated_at DESC LIMIT {st.session_state.deploy_page_size} "
             f"OFFSET {(st.session_state.deploy_page - 1) * st.session_state.deploy_page_size}")
    result = pg.execute_query(query)

    # è·å–æ€»è®°å½•æ•°ç”¨äºåˆ¤æ–­æ˜¯å¦å¯ä»¥ç¿»é¡µ
    count_query = "SELECT COUNT(*) FROM flow " + sql
    total_count = pg.execute_query(count_query)[0][0]

    pg.commit()
    st.session_state.deploy_data = (result, total_count)


def change_page_to_1():
    st.session_state.deploy_page = 1


class DeploymentPage:
    def __init__(self):
        # åˆå§‹åŒ–åˆ†é¡µçŠ¶æ€
        init_session_state('deploy_page', 1)
        init_session_state('deploy_data', None)
        init_session_state('deploy_page_size', 20)
        self.input_id = ("ChatInput", "Webhook", "TextInput")
        self.env_label = {"dev": "dev", "pro": "production", "test": "test", "beta": "stage"}
        self.fuse_table = "prompts"
        self.fuse_project_id = "cmbahi0nx00ympp085f23z64w"
        self.sqlite_op = get_sqlite()

    def get_version(self, env, current_user_id):
        new_version_pre = f"{datetime.now().strftime('%Y%m%d')}"
        with self.sqlite_op:
            last_version_info = self.sqlite_op.execute_query(
                "SELECT version FROM flow_history where environment=? and user_id=? order by created_at desc limit 1",
                (env, current_user_id))
            self.sqlite_op.commit()
            if not last_version_info:
                last_version_info = "20150618.0"
                self.sqlite_op.execute_update("insert into flow_history(name,version,environment, user_id,old_id) "
                                              "values (?,?,?,?,?)", ("", last_version_info, env, current_user_id, ""))
                return last_version_info, f"{new_version_pre}.1"
            else:
                last_version = last_version_info[0]['version']
                old_pre, old_suffix = last_version.split(".")
                if old_pre == new_version_pre:
                    new_version = f"{new_version_pre}.{int(old_suffix) + 1}"
                else:
                    new_version = f"{new_version_pre}.1"
                return last_version, new_version

    def deployment_page(self):
        init_pg()
        tabs = st.tabs(["å¤‡ä»½ç®¡ç†", "flowä¸Šçº¿", "åˆ·æ–°run_flow", "ç»„ä»¶langfuseæ ‡ç­¾æ›¿æ¢"])
        with tabs[0]:
            self.manage_backup()
        with tabs[1]:
            self.upload_flows()
        with tabs[2]:
            self.flush_run_flow()
        with tabs[3]:
            self.flush_label()

    @st.fragment
    def manage_backup(self):
        st.caption("æœ¬é¡µé¢ä¸»è¦æ˜¯ç”¨äºç®¡ç†å¤‡ä»½ç›¸å…³çš„æ•°æ®")
        selection = st.segmented_control(
            "1.è¯·é€‰æ‹©è¦ç®¡ç†çš„ç¯å¢ƒ", (("å¼€å‘", "dev"), ("æµ‹è¯•", "test"), ("beta", "beta"), ("æ­£å¼", "pro")),
            selection_mode="single", format_func=lambda x: x[0], key="manage_backup"
        )
        if selection is None:
            return
        current_user_info = get_env_pg_user_info(selection[1])
        current_user_id = get_user_id(selection[1], current_user_info.username)
        result = self.sqlite_op.execute_query(
            "SELECT version, group_concat(name, ' | ') as flow_op, created_at FROM flow_history where environment=? "
            "and user_id=? "
            "group by version order by created_at desc limit 10", (selection[1], current_user_id))
        self.sqlite_op.commit()
        if not result:
            st.warning("å½“å‰ç¯å¢ƒæ²¡æœ‰å¤‡ä»½æ•°æ®")
            return
        fuse_data = self.sqlite_op.execute_query(
            "select history as version, group_concat(name, ' | ') as fuse_op from fuse_history where label=? and operation!=? "
            "group by history order by created_at desc limit 10",
            (selection[1], 'init'))
        self.sqlite_op.commit()

        st.write("2.è¯·ä»ä¸‹é¢çš„è¡¨æ ¼é‡Œçš„æœ€å·¦è¾¹åˆ—å‹¾é€‰éœ€è¦å›é€€çš„ç‰ˆæœ¬æ•°æ®")
        st.caption("ä¸‹é¢çš„æ“ä½œæ˜¯å°†æ•°æ®è¿˜åŸåˆ°é€‰å®šç‰ˆæœ¬æ“ä½œä¹‹åçš„æ•°æ®çŠ¶æ€")
        order_data = pd.DataFrame(result)
        f_data = pd.DataFrame(fuse_data)
        merged_data = pd.merge(order_data, f_data, on='version', how='left').fillna("")
        newest_version = result[0]['version']
        merged_data.columns = ["ç‰ˆæœ¬", "æ“ä½œçš„æµåç§°", "åˆ›å»ºæ—¶é—´", "æ“ä½œçš„æç¤ºè¯"]
        data = st.dataframe(merged_data, on_select='rerun', selection_mode="single-row",
                            column_order=["ç‰ˆæœ¬", "æ“ä½œçš„æµåç§°", "æ“ä½œçš„æç¤ºè¯", "åˆ›å»ºæ—¶é—´", ])
        selected_data = data['selection']['rows']
        if not selected_data:
            return
        self.backup_version(merged_data.iloc[selected_data[0], :]['ç‰ˆæœ¬'], newest_version, selection[1],
                            current_user_id)

    @st.dialog("langflowç‰ˆæœ¬å›æº¯", width="large")
    def backup_version(self, version_info, newest_version, env, current_user_id):
        if newest_version == version_info:
            st.warning(f"å½“å‰ç‰ˆæœ¬æ•°æ®å·²ç»æ˜¯{newest_version}æ•°æ®")
            return
        st.warning(
            f"æ‚¨å³å°†ä»ç‰ˆæœ¬:**:red[{newest_version}]** å›æº¯åˆ°ç‰ˆæœ¬:**:red[{version_info}]**ï¼Œä¸­é—´ç‰ˆæœ¬æ•°æ®å°†ä¼šè¢«åˆ é™¤ï¼Œè¯·è°¨æ…æ“ä½œ")

        # flow
        history_flow_data = self.sqlite_op.execute_query(
            "select * from flow_history where environment=? and version > ? "
            "and version <= ? and user_id=? order by version desc",
            (env, version_info, newest_version, current_user_id))
        self.sqlite_op.commit()
        # å¯»æ‰¾å›æº¯æ•°æ®
        op_data = {}
        for data in history_flow_data:
            name = data['name']
            if not data['is_exist']:
                data['delete'] = True
            else:
                data['delete'] = False
            op_data[name] = data
        st.subheader("å³å°†å›æº¯çš„flowæ•°æ®å¦‚ä¸‹:")
        st.dataframe(pd.DataFrame(op_data.values()),
                     column_order=['name', 'delete', 'version', 'description', 'environment', 'created_at'])

        # fuse
        fuse_data = self.sqlite_op.execute_query(
            "select * from fuse_history where label=? and history > ? and history <= ?"
            "order by history desc",
            (env, version_info, newest_version))

        self.sqlite_op.commit()
        wait_update_fuse = {}
        for data in fuse_data:
            match data['operation']:
                case 'same':
                    continue
                case 'remove':  # æ–°æ¯”ä¹…å°‘ï¼Œè¿˜åŸæ—§çš„å°±å¾—æ–°å¢
                    wait_update_fuse[data['name']] = data
                case 'add':  # æ–°æ¯”ä¹…å¤šï¼Œè¿˜åŸæ—§çš„å°±å¾—åˆ é™¤
                    wait_update_fuse[data['name']] = data
                case 'change':  # è¿˜åŸæ—§çš„å°±ä»¥æ—§çš„ä¸ºå‡†
                    wait_update_fuse[data['name']] = data

        st.subheader(f"ä¸ºä¿è¯å®‰å…¨ï¼Œè¯·æ‰‹åŠ¨æŠŠ{env}ç¯å¢ƒçš„fuseæŒ‰ç…§å¦‚ä¸‹æŒ‡ä»¤è¿›è¡Œæ“ä½œ")
        for k,data in wait_update_fuse.items():
            match data['operation']:
                case 'remove':
                    st.warning(f'{env}ç¯å¢ƒæ–°å¢æç¤ºè¯ :orange[{data["name"]}] ç‰ˆæœ¬ä¸ºâ­ï¸:blue[{data["version"]}]')
                case 'add':
                    st.warning(f'{env}ç¯å¢ƒåˆ é™¤ :orange[{data["name"]}] å¯¹åº”ç‰ˆæœ¬ä¸ºâ­ï¸:blue[{data["version"]}]çš„{env}æ ‡ç­¾')
                case 'change':
                    st.warning(f"{env}ç¯å¢ƒæŠŠæç¤ºè¯ :orange[{data["name"]}] çš„{env}æ ‡ç­¾æ”¹åˆ°ç‰ˆæœ¬â­ï¸:blue[{data["version"]}]ä¸Šé¢")
        if st.button("ç¡®è®¤å›æº¯åä¸å¯æ’¤é”€", type="primary", key="submit8"):
            self.execute_backup(op_data, current_user_id, env, version_info)

    def execute_backup(self, op_data, current_user_id, env, version_info):
        pg = get_env_pg(env)
        folder_info = get_folder_info_by_sql(env, current_user_id)
        folder_dic = {f[1]: f[0] for f in folder_info}
        for flow_name, flow_data in op_data.items():
            if flow_data['delete']:
                try:
                    pg.execute_update("delete from flow where name=%s and user_id=%s", (flow_name, current_user_id))
                except Exception as e:
                    st.error(f"æ•°æ®å›æº¯å¤±è´¥ï¼Œæ¸…é™¤æ•°æ®å‘ç”Ÿæ„å¤–ï¼š{e}")
                    pg.rollback()
                    return
            else:
                folder_name = folder_dic.get(flow_data['folder_id'])
                if not folder_name:
                    # todo åˆ›å»ºè¢«åˆ é™¤çš„ç›®å½•
                    st.error(f"æ•°æ®å›æº¯å¤±è´¥ï¼Œæ‰¾ä¸åˆ°idä¸º{flow_data['folder_id']}çš„ç›®å½•,è¯·æ£€æŸ¥ç›¸å…³æ•°æ®")
                    pg.rollback()
                    return
                pg_data = pg.execute_query("select * from flow where name=%s and user_id=%s",
                                           (flow_name, current_user_id),
                                           with_columns=True)
                if len(pg_data) != 1:
                    st.error(f"æ•°æ®å›æº¯å¤±è´¥ï¼Œæ‰¾ä¸åˆ°åä¸º{flow_name}çš„æ•°æ®")
                    pg.rollback()
                    return
                if pg_data[0]['id'] != flow_data['old_id']:
                    st.error(f"{flow_data['name']}æ•°æ®idä¸åŒ¹é…ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ•°æ®")
                    pg.rollback()
                    return
                update_columns = []
                update_values = []
                for k, v in pg_data[0].items():
                    f_v = flow_data.get(k, 'null')
                    if v == f_v or k in ('id', 'endpoint_name'):
                        continue
                    update_columns.append(f"{k}=%s")

                    if isinstance(v, (list, dict)):
                        if not isinstance(f_v, str):
                            update_values.append(json.dumps(f_v))
                        else:
                            update_values.append(f_v)
                    elif f_v == 'null' or k in ('updated_at',):
                        update_values.append(f_v)
                    elif v is None:
                        update_values.append(f_v)
                    else:
                        source_type = type(v)
                        update_values.append(source_type(f_v))

                sql = f"UPDATE flow SET {', '.join(update_columns)} WHERE name=%s and user_id=%s"
                try:
                    pg.execute_update(sql, tuple(update_values) + (flow_name, current_user_id))
                except Exception as e:
                    st.error(f"{flow_data['name']}æ•°æ®æ›´æ–°å¤±è´¥:{e}")
                    pg.rollback()
                    return
        try:
            self.sqlite_op.execute_update("delete from flow_history where version > ? and user_id=? and environment=?",
                                          (version_info, current_user_id, env), autocommit=False)
            self.sqlite_op.execute_update("delete from fuse_history where label=? and history > ?", (env, version_info))
        except Exception as e:
            st.error(f"æ•°æ®å›æº¯å¤±è´¥ï¼Œæ¸…é™¤å¤‡ä»½æ•°æ®å‘ç”Ÿæ„å¤–ï¼š{e}")
            pg.rollback()
            self.sqlite_op.rollback()
            return
        pg.commit()
        self.sqlite_op.commit()
        try:
            with st.spinner("åˆ·æ–°run_flowæ•°æ®ä¸­", show_time=True):
                wait_update, runflow_flow_map = self.generate_run_flow_data(pg, current_user_id)
                filter_update = {}
                set_op_data_key = set(op_data.keys())
                for wait_name in wait_update:
                    if wait_name in op_data:
                        filter_update[wait_name] = wait_update[wait_name]
                    elif runflow_flow_map[wait_name].intersection(set_op_data_key):
                        filter_update[wait_name] = wait_update[wait_name]
                self.execute_update_run_flow(filter_update, pg, current_user_id, with_button=False)
                if filter_update:
                    st.subheader("æ›´æ–°çš„run_flowæ•°æ®å¦‚ä¸‹:")
                    st.markdown(' '.join([f":orange-badge[:material/star: {one}]" for one in filter_update]))
        except Exception as e:
            st.error(f"åˆ·æ–°run_flowå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åˆ·æ–°run_flowæ•°æ®ï¼š{e}")
        st.balloons()
        st.success("æ•°æ®å›æº¯æ“ä½œæˆåŠŸ")

    @st.fragment
    def upload_flows(self):
        st.caption("æœ¬é¡µé¢ä¸»è¦æ˜¯ç”¨äºæŠŠflowä»aç¯å¢ƒåŒæ­¥åˆ°bç¯å¢ƒï¼Œåœ¨ä¸Šçº¿çš„æ—¶å€™ä¼šè‡ªåŠ¨å½¢æˆæ“ä½œç‰ˆæœ¬å¤‡ä»½ï¼Œ"
                   "åœ¨ä¸Šçº¿çš„æ—¶å€™ä¼šå¯¹æç¤ºè¯æ ‡ç­¾ç»Ÿä¸€å˜æˆå½“å‰ç¯å¢ƒçš„æ ‡ç­¾ï¼Œæ¸…é™¤äº†fileSelectçš„é»˜è®¤å€¼ï¼ŒæŠŠrun_flowçš„optionsç½®ä¸ºé€‰ä¸­çš„æ•°æ®ï¼Œ"
                   "æ“ä½œå®Œæˆåè®°å¾—å»åˆ·æ–°run_flow")
        select_env = st.segmented_control("1.è¯·é€‰æ‹©æ‚¨çš„å‘å¸ƒç¯å¢ƒ", (
            ("å¼€å‘->æµ‹è¯•", "dev", "test"),
            ("æµ‹è¯•->beta", "test", "beta"),
            ("beta->ç”Ÿäº§", "beta", "pro"),
            ("ç”Ÿäº§->æµ‹è¯•", "pro", "test"),
        ), format_func=lambda option: option[0], key="select_env", on_change=change_page_to_1)
        if not select_env:
            return

        current_env = select_env[1]
        future_env = select_env[2]
        current_user_info = get_env_pg_user_info(current_env)
        st.warning(
            f"æ‚¨å½“å‰é€‰æ‹©çš„ç¯å¢ƒæ˜¯:**:red[{current_env}]**ï¼Œ"
            f"æ‚¨è¦å‘å¸ƒçš„ç¯å¢ƒæ˜¯:**:red[{future_env}]**ï¼Œ"
            f"æ‚¨æ­£åœ¨ä½¿ç”¨çš„ç”¨æˆ·æ˜¯:**:red[{current_user_info.username}]**"
        )

        st.subheader("æ•°æ®å±•ç¤º")

        select_show_way = st.segmented_control("2.è¯·é€‰æ‹©æ•°æ®å±•ç¤ºæ–¹å¼", (
            ("æŒ‰æ›´æ–°æ’åºæ—¶é—´å±•ç¤º", "time"),
            ("æŒ‰ç›®å½•é€‰æ‹©å±•ç¤º", "dir"),
        ), format_func=lambda option: option[0], key="select_display", on_change=change_page_to_1)
        if not select_show_way:
            return
        user_id = get_user_id(current_env, current_user_info.username)
        select_folder = None
        select_time = None
        if select_show_way[1] == "dir":
            # é€‰æ‹©æ–‡ä»¶å¤¹
            select_folder = st.pills("**:red[é€‰æ‹©æ–‡ä»¶å¤¹]**", get_folder_info_by_sql(current_env, user_id),
                                     selection_mode="single",
                                     format_func=lambda option: option[0], on_change=change_page_to_1)
            if not select_folder:
                return
            select_folder = select_folder[1]
        else:
            select_time = st.pills("**:red[é€‰æ‹©æ—¶é—´èŒƒå›´]**", (
                ("æœ€è¿‘1å¤©", 1), ("æœ€è¿‘3å¤©", 3), ("æœ€è¿‘7å¤©", 7), ("æœ€è¿‘30å¤©", 30)
            ), selection_mode="single", format_func=lambda option: option[0], on_change=change_page_to_1)
            if not select_time:
                return
            select_time = datetime.now() - timedelta(days=select_time[1])

        # è·å–æ•°æ®
        search_term = st.text_input(label="æœç´¢æµç¨‹åç§°", placeholder="è¯·è¾“å…¥æŸ¥è¯¢çš„æµç¨‹åç§°", key="search_term",
                                    label_visibility="collapsed", on_change=change_page_to_1)
        get_data(search_term, user_id, select_folder, current_env, select_time)
        if st.session_state.deploy_data is None:
            return
        # è®¡ç®—æ€»é¡µæ•°
        total_pages = math.ceil(st.session_state.deploy_data[1] / st.session_state.deploy_page_size)

        df = pd.DataFrame(st.session_state.deploy_data[0],
                          columns=['name', 'folder_name', 'description', 'updated_at', 'endpoint_name', 'gradient',
                                   'is_component', 'tags', 'data'])
        # # åˆ†é¡µæ§åˆ¶æŒ‰é’®
        col1, col2, col3 = st.columns([1, 5, 1])
        with col1:
            if st.button("ä¸Šä¸€é¡µ", disabled=st.session_state.deploy_page <= 1, use_container_width=True,
                         key="prev_page"):
                st.session_state.deploy_page -= 1
                if st.session_state.deploy_page < 1:
                    st.session_state.deploy_page = 1
                st.rerun()
        with col2:
            st.button(f"å…±æœ‰ {total_pages} é¡µï¼Œå½“å‰é¡µ: {st.session_state.deploy_page}", use_container_width=True,
                      disabled=True,
                      type="tertiary", key="current_page")
        with col3:
            if st.button("ä¸‹ä¸€é¡µ", use_container_width=True, key="next_page",
                         disabled=st.session_state.deploy_page >= total_pages):
                st.session_state.deploy_page += 1
                st.rerun()
        self.show_data(df, future_env)

    @st.fragment
    def flush_run_flow(self):
        st.caption("æœ¬é¡µé¢ä¸»è¦æ˜¯ç”¨äºåˆ·æ–°run_flowæ•°æ®ï¼Œä¼šå°è¯•æ›´æ–°æ•°æ®ï¼Œè‡ªåŠ¨è¿çº¿")
        selection = st.segmented_control(
            "1.è¯·é€‰æ‹©åˆ·æ–°ç¯å¢ƒ", (("å¼€å‘", "dev"), ("æµ‹è¯•", "test"), ("beta", "beta"), ("æ­£å¼", "pro")),
            selection_mode="single", format_func=lambda x: x[0], key="flush_rn_flow"
        )
        if selection is None:
            return
        current_env = selection[1]
        current_user_info = get_env_pg_user_info(current_env)
        st.warning(
            f"æ‚¨å½“å‰é€‰æ‹©çš„ç¯å¢ƒæ˜¯:**:red[{current_env}]**ï¼Œ"
            f"æ‚¨å½“å‰é€‰æ‹©çš„ç”¨æˆ·æ˜¯:**:red[{current_user_info.username}]**"
        )
        st.write("2.æŸ¥è¯¢ç›¸å…³ä¿¡æ¯")
        if not st.button(
                f"æŸ¥æ‰¾ç”¨æˆ· {current_user_info.username} ä¸‹çš„run_flow", type="primary", key="submit3"):
            return
        current_user_id = get_user_id(current_env, current_user_info.username)
        current_pg = get_env_pg(current_env)

        wait_update, _ = self.generate_run_flow_data(current_pg, current_user_id)
        self.execute_update_run_flow(wait_update, current_pg, current_user_id)

    def generate_run_flow_data(self, current_pg, current_user_id):
        my_bar = st.progress(0.0, text="å¼€å§‹æŸ¥æ‰¾è¦å¤„ç†çš„æ•°æ®")
        flow_list = current_pg.execute_query("""select flow.data as data, flow.name as flow_name, folder.name as folder from flow 
                left join folder on flow.user_id=folder.user_id and flow.folder_id=folder.id WHERE flow.is_component=False 
                and jsonb_path_exists(data::jsonb,
              '$.nodes[*] ? (
                @.id starts with "RunFlow"
              )'
            ) and flow.user_id=%s and RIGHT(folder.name, 1)='*';""", (current_user_id,), with_columns=True)
        current_pg.commit()
        my_table = st.dataframe([])
        length = len(flow_list)

        wait_update = {}
        runflow_flow_map = defaultdict(set)
        for _index, run_flow in enumerate(flow_list):
            # ä¸€ä¸ªå«æœ‰run_flowçš„flow
            nodes = run_flow['data']['nodes']
            name = run_flow['flow_name']
            folder_name = run_flow['folder']
            my_table.add_rows(pd.DataFrame([{"ç›®å½•": folder_name, "æµç¨‹": name, "runflowè¦è°ƒç”¨çš„flow": ""}]))

            run_flow_new_template_keys = dict()

            replace_edge_target = {}
            my_bar.progress(round(_index / length, 1), text=f"æ­£åœ¨å¤„ç†  :red[{name}]")
            # æ›´æ–°èŠ‚ç‚¹
            for node in nodes:
                if node['id'].startswith("RunFlow"):
                    # è¿™æ˜¯è¯¥flowçš„ä¸€ä¸ªrun_flow
                    template = node["data"]["node"]["template"]
                    # original_template_key = set(template.keys())
                    flow_name_selected = template["flow_name_selected"]["value"]
                    runflow_flow_map[name].add(flow_name_selected)

                    # æ‰¾åˆ°run_flowé‡Œé¢è¢«å¼•ç”¨çš„flow
                    vertex_data = current_pg.execute_query("select data from flow where name=%s and user_id=%s",
                                                           (flow_name_selected, current_user_id))
                    current_pg.commit()
                    if not vertex_data:
                        my_table.add_rows([{"ç›®å½•": "", "æµç¨‹": "", "runflowè¦è°ƒç”¨çš„flow": f"ğŸš«{flow_name_selected}"}])
                        st.error(f"ç›®å½•:ğŸ‘‰{folder_name}ğŸ‘ˆçš„flow:ğŸ‘‰{name}ğŸ‘ˆæ‰¾ä¸åˆ°è¢«å¼•ç”¨çš„flow:ğŸ‘‰{flow_name_selected}ğŸ‘ˆ")
                        continue
                    my_table.add_rows([{"ç›®å½•": "", "æµç¨‹": "", "runflowè¦è°ƒç”¨çš„flow": f"{flow_name_selected}"}])
                    vertex_nodes = vertex_data[0][0]['nodes']
                    new_fields = []
                    # éå†è¢«å¼•ç”¨çš„flow
                    for vertex_node in vertex_nodes:
                        # å¯»æ‰¾è¾“å…¥èŠ‚ç‚¹
                        is_input = any(input_name in vertex_node['id'] for input_name in self.input_id)
                        if not is_input:
                            continue
                        # æ‰¾åˆ°è¾“å…¥èŠ‚ç‚¹
                        field_template = vertex_node['data']['node']['template']
                        field_order = vertex_node['data'].get("node", {}).get("field_order", [])
                        if field_order and field_template:
                            new_vertex_inputs = [
                                dict(
                                    {
                                        **field_template[input_name],
                                        "display_name": vertex_node['data'].get("node", {})[
                                                            'display_name'] + " - " +
                                                        field_template[input_name][
                                                            "display_name"],
                                        "name": f"{vertex_node['id']}~{input_name}",
                                        "tool_mode": not (field_template[input_name].get("advanced", False)),
                                    }
                                )
                                for input_name in field_order
                                if input_name in field_template
                            ]
                            new_fields += new_vertex_inputs
                    old_fields = [
                        field
                        for field in template
                        if field not in [new_field["name"] for new_field in new_fields] + ["code", "_type",
                                                                                           "flow_name_selected",
                                                                                           "session_id"]
                    ]

                    # å¦‚æœæ—§èŠ‚ç‚¹çš„å’Œæ–°èŠ‚ç‚¹çš„æ•°é‡éƒ½ä¸º1ä¸”display_nameç›¸åŒï¼Œå¯ä»¥æŠŠçº¿ç›´æ¥è¿èµ·æ¥
                    if len(new_fields) == len(old_fields) == 1:
                        if new_fields[0]["display_name"] == old_fields[0]["display_name"]:
                            replace_edge_target[old_fields[0]['name']] = new_fields[0]['name']

                    # åˆ é™¤å­—æ®µ
                    for field in old_fields:
                        template.pop(field, None)
                    # æ–°å¢å­—æ®µ
                    for field in new_fields:
                        template[field["name"]] = field
                    # new_template_key = set(template.keys())
                    # if u_in := original_template_key.symmetric_difference(new_template_key):
                    #     need_update = True
                    run_flow_new_template_keys[node["id"]] = set(template.keys())

            # æ›´æ–°çº¿
            new_edges = []
            for edge in run_flow['data']['edges']:
                # å¦‚æœè¯¥çº¿çš„targetæ˜¯run_flow
                if new_keys := run_flow_new_template_keys.get(edge['target']):
                    old_target_key = edge["data"]["targetHandle"]["fieldName"]
                    # å¦‚æœè¯¥çº¿çš„targetå·²ç»ä¸å­˜åœ¨äº†
                    if old_target_key not in new_keys:
                        # å¦‚æœè¯¥çº¿çš„targetå¯ä»¥è¢«æ›¿æ¢
                        if new_target_key := replace_edge_target.get(old_target_key):
                            edge["data"]["targetHandle"]["fieldName"] = new_target_key
                        else:
                            # åˆ é™¤è¯¥çº¿
                            continue
                new_edges.append(edge)
            run_flow['data']['edges'] = new_edges

            wait_update[name] = json.dumps(run_flow['data'])
        my_bar.empty()
        return wait_update, runflow_flow_map

    @st.fragment
    def execute_update_run_flow(self, wait_update, current_pg, current_user_id, with_button=True):
        if with_button and not st.button("æäº¤æ›´æ–°", type="primary", key="submit7"):
            return
        for name, data in wait_update.items():
            current_pg.execute_update("update flow set data=%s where name=%s and user_id=%s",
                                      (data, name, current_user_id))
            current_pg.commit()
            if with_button:
                st.success(f"{name} æ›´æ–°æˆåŠŸ", icon='ğŸ‰')
        st.toast("åˆ·æ–°å®Œæˆ", icon='ğŸ‰')
        st.balloons()

    @st.fragment
    def flush_label(self):
        st.caption("æœ¬é¡µé¢ä¸»è¦æ˜¯ç”¨äºåˆ·æ–°Langfuse2çš„labelæ ‡ç­¾ï¼Œå°†ä¸æ˜¯æŒ‡å®šæ ‡ç­¾çš„æ•°æ®åˆ·æ–°åˆ°æŒ‡å®šæ ‡ç­¾ä¸Šå»")
        selection = st.segmented_control(
            "1.è¯·é€‰æ‹©ç¯å¢ƒ", (("å¼€å‘", "dev"), ("æµ‹è¯•", "test"), ("beta", "beta"), ("æ­£å¼", "pro")),
            selection_mode="single", format_func=lambda x: x[0], key="flush_label"
        )
        if selection is None:
            return
        new_label = st.pills("2.è¯·é€‰æ‹©è¦æ›´æ–°æ ‡ç­¾", ['dev', 'test', 'stage', 'production'], selection_mode="single",
                             key="future_label")
        if not new_label:
            return
        current_env = selection[1]
        current_user_info = get_env_pg_user_info(current_env)
        st.warning(
            f"æ‚¨å½“å‰é€‰æ‹©çš„ç¯å¢ƒæ˜¯:**:red[{current_env}]**ï¼Œ"
            f"æ‚¨å½“å‰é€‰æ‹©çš„ç”¨æˆ·æ˜¯:**:red[{current_user_info.username}]**ï¼Œ"
            f"æ‚¨è¦æ›´æ–°çš„æ ‡ç­¾æ˜¯:**:red[{new_label}]**ï¼Œ"f""
        )
        current_pg = get_env_pg(current_env)
        current_user_id = get_user_id(current_env, current_user_info.username)

        with st.spinner("æ•°æ®åŠ è½½ä¸­...", show_time=True):
            flow_list = current_pg.execute_query(f"""select flow.id, flow.name, flow.data, folder.name as folder from flow 
             left join folder on flow.user_id=folder.user_id and flow.folder_id=folder.id WHERE flow.is_component=False 
             and jsonb_path_exists(data::jsonb,
                  '$.nodes[*] ? (
                    @.id starts with "LangfusePrompt2" && @.data.node.template.label.value != "{new_label}"
                  )'
                ) and flow.user_id=%s and RIGHT(folder.name, 1)='*'""", (current_user_id,), with_columns=True)
            current_pg.commit()
        table = st.dataframe([], use_container_width=True, hide_index=False)

        wait_update_flow = {}
        show_warning = False
        for flow in flow_list:
            flow_id = flow['id']
            flow_name = flow['name']
            flow_data = flow['data']
            folder_name = flow['folder']
            table.add_rows([{
                'ç›®å½•å': folder_name,
                'flow_name': "",
                'æç¤ºè¯å': "",
                'åŸå§‹æ ‡ç­¾': "",
                'å¾…æ›´æ–°æ ‡ç­¾': "",
            }])

            for node in flow_data['nodes']:
                if node['id'].startswith("LangfusePrompt2"):
                    node_template = node['data']['node']['template']
                    if 'label' not in node_template:
                        # todo å‘ç°å¼‚å¸¸æ•°æ®
                        st.error(f"å‘ç°å¼‚å¸¸æ•°æ®ï¼Œflow_id={flow_id},flow_name={flow_name},node_id={node['id']}")
                        continue

                    original_label = node_template['label']['value']
                    original_prompt_name = node_template['self_prompt_name']['value'] or node_template['prompt_name'][
                        'value']
                    if original_prompt_name:
                        show_warning = True
                    table.add_rows([{
                        'ç›®å½•å': "",
                        'flow_name': flow_name,
                        'æç¤ºè¯å': original_prompt_name,
                        'åŸå§‹æ ‡ç­¾': original_label,
                        'å¾…æ›´æ–°æ ‡ç­¾': f'{new_label}',
                    }])
                    node_template['label']['value'] = new_label
            wait_update_flow[flow_id] = flow_data
        if show_warning:
            st.warning("éƒ¨åˆ†æç¤ºè¯åæ²¡æœ‰å€¼çš„æ˜¯ç”±äºå®ƒçš„è¾“å…¥æ˜¯å‰ä¸€ä¸ªç»„ä»¶ä¼ çš„", icon="âš ï¸")
        self.update_flow_label(wait_update_flow, current_pg, new_label)

    @st.fragment
    def update_flow_label(self, wait_update_flow, current_pg, new_label):
        if not wait_update_flow:
            st.warning(f"æ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ä¸æ˜¯{new_label}çš„æ•°æ®", icon='âš ï¸')
            return
        if st.button("æ›´æ–°", type="primary", key="update_flow_label"):
            my_bar = st.progress(0.0, text="å¼€å§‹åˆ·æ–°æ•°æ®")
            length = len(wait_update_flow)
            begin = 0
            for flow_id, flow_data in wait_update_flow.items():
                my_bar.progress(round(begin / length, 1), text=f"å¼€å§‹åˆ·æ–°æ•°æ®{flow_id}")
                current_pg.execute_update("update flow set data=%s where id=%s",
                                          (json.dumps(flow_data), flow_id))
                current_pg.commit()
                st.success(f"{flow_id}æ›´æ–°æˆåŠŸ", icon='ğŸ‰')
                begin += 1
            my_bar.empty()
            st.toast(f"æ›´æ–°æˆåŠŸ", icon='ğŸ‰')

    @staticmethod
    def check_description(description):
        return ['background-color: red' if not re.match(r'\[.*?].*?-\d{8}-\d{2}:\d{2}', des) else '' for des in
                description]

    @st.fragment
    def show_data(self, df, future_env):
        show_data = df.iloc[:, :-1]
        styled_df = show_data.style.apply(self.check_description, subset=['description'])
        tt = st.dataframe(data=styled_df, selection_mode='multi-row', use_container_width=True, hide_index=False,
                          column_order=['folder_name', 'name', 'description', 'updated_at'], on_select='rerun')

        if tt['selection']['rows'] and st.button("ç¡®è®¤", type="primary", key="submit1"):
            selected = df.iloc[tt['selection']['rows']]
            self.online_flow(selected, future_env)
            return selected

    # ä¸Šçº¿æµç¨‹
    @st.dialog("ä¸Šçº¿æµç¨‹", width="large")
    def online_flow(self, selected, future_env):
        st.caption("ä½ å°†æŠŠä¸‹é¢çš„æµç¨‹éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼Œç‚¹å‡»æäº¤æŒ‰é’®ä»¥æ‰§è¡Œ")
        st.write(selected.iloc[:, :3])
        future_user_info = get_env_pg_user_info(future_env)
        # è·å–token
        langflow_token = login_langflow(future_user_info.username, future_user_info.password, future_user_info.url)

        if st.button("æäº¤ä¸Šçº¿", type="primary", key="submit2"):
            self.submit(selected, langflow_token, future_env, future_user_info)

    @st.fragment
    def submit(self, selected, langflow_token, future_env, future_user_info):
        future_user_id = get_user_id(future_env, future_user_info.username)
        last_version, new_version = self.get_version(future_env, future_user_id)
        st.header(
            "è¯·ç¡®è®¤æœ¬æ¬¡æ“ä½œç‰ˆæœ¬å·: :red[{}]  ä¸Šä¸ªæ“ä½œç‰ˆæœ¬å·ä¸º: :blue[{}]".format(new_version,
                                                                                 last_version or "20150618.0"))
        # è·å–ç›®å½•ä¿¡æ¯
        selected_dirs = selected['folder_name'].unique().tolist()
        # æŸ¥çœ‹ç›®å½•æ˜¯å¦å­˜åœ¨
        dir_info = get_folder_info_by_sql(future_env, user_id=future_user_id, with_backups=True)
        dir_dict = dict(dir_info)  # {name:id}
        for selected_dir in selected_dirs:
            if selected_dir not in dir_dict:
                st.error(f"ç›®å½•{selected_dir}ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºç›®å½•")
                if st.button(f"åˆ›å»ºç›®å½•->{selected_dir}", type="primary", key="submit6"):
                    dir_id = create_folder_by_api(langflow_token, selected_dir, future_user_info.url)
                    if not dir_id:
                        return
                    dir_dict[selected_dir] = dir_id
                    st.rerun()
                else:
                    return

        if not st.button(
                f"ç»§ç»­å°†flowæäº¤åˆ° {future_user_info.username} ç”¨æˆ·ä¸‹çš„ {selected_dirs} ç›®å½•",
                type="primary", key="submit3"):
            return
        self._backup_langfuse(last_version, new_version, future_env)
        back_dir_id = dir_dict.get("å¤‡ä»½", None)
        if not back_dir_id:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            back_dir_id = create_folder_by_api(langflow_token, "å¤‡ä»½", future_user_info.url)
            if not back_dir_id:
                return
        data = selected.to_dict(orient="records")
        percent_complete = 0
        my_bar = st.progress(percent_complete, text="æ­£åœ¨å¼€å§‹å¯¼å…¥...")
        future_pg = get_env_pg(future_env)

        success_info = []
        length = len(data)
        st.write(f"ä¸€å…±æœ‰{length}æ¡æ•°æ®")
        back_columns = ['data', 'name', 'description', 'user_id', 'is_component', 'updated_at', 'icon',
                        'icon_bg_color',
                        'folder_id', 'endpoint_name', 'webhook', 'gradient', 'tags', 'locked', 'fs_path',
                        'access_type',
                        'mcp_enabled', 'action_name', 'action_description', 'version', 'environment', 'created_at',
                        'is_exist', 'old_id']

        for one_index, one in enumerate(data):
            folder_id = dir_dict[one['folder_name']]
            percent_complete = round(one_index / length, 1)
            exist = future_pg.execute_query(f"select * from flow where name=%s and user_id=%s",
                                            (one['name'], future_user_id), with_columns=True)
            future_pg.commit()
            if len(exist) > 0:
                exist_flow = exist[0]
                exist_id = exist_flow['id']
                new_id = str(uuid4())
                # å¤‡ä»½å­˜åœ¨çš„flow
                back_name = f"{one['name']}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
                my_bar.progress(percent_complete, text=f"å¼€å§‹å¤‡ä»½ {back_name}...")
                future_pg.execute_update(f"update flow set id=%s, name=%s,folder_id=%s where id=%s", (
                    new_id, back_name, back_dir_id, exist_id))
                future_pg.commit()

                # ä¿å­˜ç‰ˆæœ¬æ•°æ®
                values = [exist_flow.get(c) for c in back_columns]
                values = [json.dumps(v) if isinstance(v, (dict, list)) else v for v in values]
                values[-5] = new_version
                values[-4] = future_env
                values[-3] = datetime.now()
                values[-2] = True
                values[-1] = exist_id
                self.sqlite_op.execute_update(
                    f"insert into flow_history({','.join(back_columns)}) values({','.join(['?'] * len(back_columns))})",
                    tuple(values))
                self.sqlite_op.commit()
                my_bar.progress(percent_complete, text=f"å¤‡ä»½ {back_name} æˆåŠŸï¼Œæ­£åœ¨å¯¼å…¥ {one['name']} ...")

                # æ–°å»ºflow
                for k in exist_flow.keys():
                    if up_value := one.get(k):
                        exist_flow[k] = up_value
                exist_flow['updated_at'] = datetime.now()
                # ä¿®æ­£ä¸€äº›æ•°æ®
                flow_data = one['data']
                for node in flow_data['nodes']:
                    node_template = node["data"]["node"]["template"]
                    # ä¿®æ”¹langfuse2çš„label
                    if node['id'].startswith("LangfusePrompt2"):
                        if 'label' not in node_template:
                            # todo å‘ç°å¼‚å¸¸æ•°æ®
                            st.warning(f"{one['name']}çš„LangfusePrompt2æœ‰å¼‚å¸¸æ•°æ®ï¼Œè¯·æ£€æŸ¥label")
                            continue
                        new_label = self.env_label[future_env]
                        node_template['label']['value'] = new_label
                    elif node['id'].startswith("RunFlow"):
                        value = node_template["flow_name_selected"]["value"]
                        node_template["flow_name_selected"]["options"] = [value]
                    elif node['id'].startswith("ChatInput"):
                        if node["data"]['node']['display_name'] == 'FileSelect':
                            if 'files' not in node_template:
                                st.error(f"{one['name']}çš„ChatInputæœ‰å¼‚å¸¸æ•°æ®ï¼Œè¯·æ£€æŸ¥files")
                                continue
                            node_template['files']['file_path'] = []
                            node_template['files']['value'] = ""

                exist_flow['data'] = json.dumps(flow_data)
                exist_flow['folder_id'] = folder_id
                exist_flow['tags'] = json.dumps(exist_flow['tags']) if exist_flow['tags'] is not None else None
                columns, values = zip(*exist_flow.items())
                values = list(values)
                new_columns = ", ".join(columns)
                sql = f"insert into flow({new_columns}) values({', '.join(['%s'] * len(values))})"
                try:
                    future_pg.execute_update(sql, tuple(values))
                except Exception as e:
                    if "unique_flow_endpoint_name" in str(e):
                        index_ = columns.index("endpoint_name")
                        values[index_] = None
                        future_pg.execute_update(sql, tuple(values))
                success_info.append((exist_flow['name'], exist_id))
            else:
                my_bar.progress(percent_complete, text=f"æ­£åœ¨å¯¼å…¥ {one['name']} ...")
                response = create_new_flow_by_api(langflow_token, folder_id, one, future_user_info.url)
                if response:
                    success_info.append((response['name'], response['id']))

                    # ä¿å­˜ç‰ˆæœ¬æ•°æ®
                    values = [response.get(c) for c in back_columns]
                    values = [json.dumps(v) if isinstance(v, (dict, list)) else v for v in values]
                    values[-5] = new_version
                    values[-4] = future_env
                    values[-3] = datetime.now()
                    values[-2] = False
                    values[-1] = response['id']
                    self.sqlite_op.execute_update(
                        f"insert into flow_history({','.join(back_columns)}) values({','.join(['?'] * len(back_columns))})",
                        tuple(values))
                    self.sqlite_op.commit()

        my_bar.empty()
        st.success("å¯¼å…¥å®Œæˆ \n" +
                   "|  flow_name   | flow_id  |\n" +
                   "| :------: | :------: |\n" +
                   "\n".join([f"|**:red[{name}]**  | {_id}|" for name, _id in success_info]))

    def _backup_langfuse(self, old_version, new_version, env):
        # å…ˆå¤‡ä»½langfuseæ•°æ®
        fuse_pg = get_fuse_pg()
        new_fuse_data = fuse_pg.execute_query(f"select version,label,p.name as name from {self.fuse_table} p,"
                                              f"unnest(p.labels) AS label where project_id='{self.fuse_project_id}' "
                                              f"AND label='{env}' order by name", with_columns=True)
        fuse_pg.commit()
        sqlite = self.sqlite_op
        # å¦‚æœæ–°ç‰ˆæœ¬æ•°æ®å·²ç»å­˜åœ¨äº†ï¼Œä¸ºäº†ä¸å¹²æ‰°ï¼Œç›´æ¥åˆ é™¤
        if sqlite.execute_query(f"select count(*) from fuse_history where label='{env}' and history>='{new_version}'"):
            sqlite.execute_update(f"delete from fuse_history where label='{env}' and history>='{new_version}'",
                                  autocommit=False)

        max_old_history = sqlite.execute_query(f"select max(history) as max_old_history from fuse_history "
                                               f"where label='{env}' and history<='{old_version}' and operation!='same'", )
        sqlite.commit()
        st.write("å¼€å§‹å¤‡ä»½langfuseæ•°æ®")

        if not max_old_history[0].get('max_old_history'):
            try:
                for one in new_fuse_data:
                    sqlite.execute_update("insert into fuse_history(id, history, name, version, label, operation) values (?,?,?,?,?,?)",
                                          (str(uuid.uuid4()), '20250618.0', one['name'], one['version'], one['label'], 'init'),
                                          autocommit=False)
                sqlite.execute_update("insert into fuse_history(id, history, label, operation) values (?,?,?,?)",
                                      (str(uuid.uuid4()), new_version, env, 'same'), autocommit=False)
                sqlite.commit()
            except Exception as e:
                sqlite.rollback()
                st.error("å¤‡ä»½fuse_historyå¤±è´¥ï¼Œè¯·é‡è¯•: {}".format(e))
                raise e
        else:
            try:
                max_old_history = max_old_history[0]['max_old_history']
                old_fuse_data = sqlite.execute_query(
                    (f"select name, version, max(history) as history, operation from fuse_history where name is not null "
                     f"and label='{env}' and history<='{max_old_history}' group by name"))
                sqlite.commit()

                # æµ‹è¯•æ•°æ®
                # new_fuse_data.pop()
                # new_fuse_data[33]['version'] = 31
                # new_fuse_data.append({'name': 'root1', 'label': env, 'version': 9})
                # st.write(new_fuse_data[33])

                new_fuse_dict = {one['name']: one['version'] for one in new_fuse_data}
                old_fuse_dict = {one['name']: one['version'] for one in old_fuse_data if one['operation'] not in ('same', 'remove')}
                diff = DeepDiff(old_fuse_dict, new_fuse_dict, view="text")
                if diff:
                    st.write('**fuseæ•°æ®å˜åŒ–å¦‚ä¸‹ï¼š**')
                    st.write(diff)
                    name_pattern = re.compile(r'root\[\'(.*?)\']')
                    for change_type, changes in diff.items():
                        match change_type:
                            case "dictionary_item_removed":
                                removed = name_pattern.findall(str(changes))
                                # æ—§çš„æœ‰æ–°çš„æ²¡æœ‰
                                for remove in removed:
                                    old_v = old_fuse_dict[remove]
                                    sqlite.execute_update(
                                        "insert into fuse_history(name, label, version, operation, history) values (?,?,?,?,?)",
                                        (remove, env, old_v, 'remove', new_version), autocommit=False)
                            case "dictionary_item_added":
                                added = name_pattern.findall(str(changes))
                                # æ–°çš„æœ‰æ—§çš„æ²¡æœ‰
                                for add in added:
                                    new_v = new_fuse_dict[add]
                                    sqlite.execute_update(
                                        "insert into fuse_history(name, label, version, operation, history) values (?,?,?,?,?)",
                                        (add, env, new_v, 'add', new_version), autocommit=False)
                            case "values_changed":
                                if 'root' in changes:
                                    for name, old_v in changes['root']['old_value'].items():
                                        sqlite.execute_update(
                                            "insert into fuse_history(name, label, version, operation, history) values (?,?,?,?,?)",
                                            (name, env, old_v, 'change', new_version), autocommit=False)
                                else:
                                    for key, value in changes.items():
                                        name = name_pattern.findall(str(key))[0]
                                        old_v = value['old_value']
                                        sqlite.execute_update(
                                            "insert into fuse_history(name, label, version, operation, history) values (?,?,?,?,?)",
                                            (name, env, old_v, 'change', new_version), autocommit=False)
                else:
                    st.warning("langfuseæ•°æ®æœªå‘ç”Ÿå˜åŒ–")
                    sqlite.execute_update("insert into fuse_history(label, operation, history) values (?,?,?)",
                                          (env, 'same', new_version), autocommit=False)
                sqlite.commit()

            except Exception as e:
                sqlite.rollback()
                st.error("å¤‡ä»½fuse_historyå¤±è´¥ï¼š{}".format(e))
                raise e

        st.success("å¤‡ä»½langfuseæ•°æ®æˆåŠŸ")


DeploymentPage().deployment_page()
